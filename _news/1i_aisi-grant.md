---
layout: post
title: Submitted AISI Systemic AI Safety Grant Application
date: 2024-11-26 12:00:00-0400
inline: false
related_posts: false
---

**Update (December 13, 2024):** We recently received notification regarding our AISI Systemic AI Safety Grants application. While our proposal received high scores in the initial review, due to the highly competitive nature of the program and its randomisation process for the top applications, we were not selected to progress to the expert assessment panel. This experience has provided valuable insights for future funding applications.

Under the guidance of my PhD supervisors Dr. Budi Arief and Prof. Shujun Li, we submitted a grant application to the AI Safety Institute's (AISI) Systemic AI Safety Grants program. Our proposal aimed to investigate the cyber security impact of fine-tuning open-source AI models and their potential implications for systemic AI safety.

The research proposal included:
- A comprehensive 12-month research plan with a budget of Â£175,000
- Investigation of security implications in fine-tuning open-source AI models
- Development of mitigation strategies for identified risks
- Creation of best practices for secure model adaptation
- Focus on systemic safety in multi-model environments

Key aspects of the proposed methodology:
1. Model Selection and Dataset Curation
   - Identification of suitable open-source AI models
   - Collection and preparation of diverse cyber security datasets
   - Development of robust evaluation metrics

2. Security Analysis and Implementation
   - Implementation of various fine-tuning techniques
   - Comprehensive vulnerability analysis
   - Assessment of safeguard effectiveness
   - Testing against various attack scenarios

3. Mitigation and Guidelines Development
   - Design of security enhancement measures
   - Creation of practical recommendations
   - Development of implementation frameworks
   - Documentation of best practices

The proposal was submitted on November 26, 2024, with research planned to commence in February 2025 if successful. The work would have been conducted at the Institute of Cyber Security for Society (iCSS) at the University of Kent, leveraging the institute's expertise in cyber security and AI.

Special acknowledgment to my supervisors for their exceptional guidance throughout the application process, helping shape both the technical aspects and broader impact of the proposed research.
